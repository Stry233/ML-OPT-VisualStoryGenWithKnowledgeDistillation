{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ukXOf93q4iSJ",
    "outputId": "3b60cc7e-d417-424a-b49e-5d2232519ac7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting SentencePiece\n",
      "  Downloading sentencepiece-0.1.98-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: SentencePiece\n",
      "Successfully installed SentencePiece-0.1.98\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0\n",
      "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.13.4 tokenizers-0.13.3 transformers-4.28.1\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.9/dist-packages (13.3.4)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.9/dist-packages (from rich) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from rich) (2.14.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.9/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich) (0.1.2)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting dill\n",
      "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from evaluate) (2.27.1)\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.9/dist-packages (from evaluate) (2023.4.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from evaluate) (1.5.3)\n",
      "Collecting responses<0.19\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from evaluate) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from evaluate) (1.22.4)\n",
      "Collecting datasets>=2.0.0\n",
      "  Downloading datasets-2.11.0-py3-none-any.whl (468 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.7/468.7 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from evaluate) (0.13.4)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from evaluate) (23.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->evaluate) (1.26.15)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->evaluate) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->evaluate) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->evaluate) (3.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->evaluate) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->evaluate) (2.8.2)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (269 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.3/269.3 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
      "Installing collected packages: xxhash, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, aiosignal, aiohttp, datasets, evaluate\n",
      "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.11.0 dill-0.3.6 evaluate-0.4.0 frozenlist-1.3.3 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0 yarl-1.9.1\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting SceneGraphParser\n",
      "  Downloading SceneGraphParser-0.1.0-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.9/dist-packages (from SceneGraphParser) (0.8.10)\n",
      "Requirement already satisfied: spacy>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from SceneGraphParser) (3.5.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.0->SceneGraphParser) (1.0.9)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.0->SceneGraphParser) (1.0.4)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.0->SceneGraphParser) (2.4.6)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.0->SceneGraphParser) (1.10.7)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.0->SceneGraphParser) (2.0.8)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.0->SceneGraphParser) (3.3.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.0->SceneGraphParser) (3.0.12)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.0->SceneGraphParser) (4.65.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.0->SceneGraphParser) (3.1.2)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.0->SceneGraphParser) (8.1.9)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.0->SceneGraphParser) (0.7.0)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.0->SceneGraphParser) (1.1.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.0->SceneGraphParser) (3.0.8)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.0->SceneGraphParser) (2.0.7)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.0->SceneGraphParser) (1.22.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.0->SceneGraphParser) (67.6.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.0->SceneGraphParser) (23.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.0->SceneGraphParser) (2.27.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.0->SceneGraphParser) (6.3.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.0->SceneGraphParser) (0.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy>=3.2.0->SceneGraphParser) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.0->SceneGraphParser) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.0->SceneGraphParser) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.0->SceneGraphParser) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.0->SceneGraphParser) (3.4)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy>=3.2.0->SceneGraphParser) (0.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy>=3.2.0->SceneGraphParser) (0.7.9)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy>=3.2.0->SceneGraphParser) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy>=3.2.0->SceneGraphParser) (2.1.2)\n",
      "Installing collected packages: SceneGraphParser\n",
      "Successfully installed SceneGraphParser-0.1.0\n",
      "2023-04-23 02:40:51.420745: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-23 02:40:51.479162: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-23 02:40:52.534525: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
      "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting en-core-web-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.9/dist-packages (from en-core-web-sm==3.5.0) (3.5.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.27.1)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.9)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.22.4)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.1)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (67.6.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.65.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.5.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.12)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.2)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: spacy in /usr/local/lib/python3.9/dist-packages (3.5.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (2.27.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy) (2.4.6)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy) (6.3.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy) (1.10.7)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy) (67.6.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (1.22.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (4.65.0)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.9/dist-packages (from spacy) (8.1.9)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.9/dist-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy) (1.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.5.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy) (2.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install SentencePiece\n",
    "!pip install transformers\n",
    "!pip install rich\n",
    "!pip install evaluate\n",
    "!pip install SceneGraphParser\n",
    "!python -m spacy download en  \n",
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kLttu6an9YCm",
    "outputId": "a553fbe9-2e05-499b-b0bc-3d56a5bdcdc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "WYtD2n9U4s-3"
   },
   "outputs": [],
   "source": [
    "# global var set\n",
    "import transformers\n",
    "# model info, change as needed\n",
    "batch_size = 26\n",
    "num_epochs = 20\n",
    "\n",
    "model_checkpoint = \"mrm8488/t5-base-finetuned-common_gen\"\n",
    "# model_checkpoint = \"t5-base\"\n",
    "# metric_name = \"f1\"\n",
    "fileTag = \"original-plutchik-v1\"\n",
    "# fileTag = \"clean-v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5HQMjxUM4iSL",
    "outputId": "dc13d804-6111-4c25-bd2b-9bb5280b65eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'A-Emotion-Data-Cleaning-Pipeline-for-Enhancing-Data-Reliability' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "!git clone https://github.com/Stry233/A-Emotion-Data-Cleaning-Pipeline-for-Enhancing-Data-Reliability.git\n",
    "trainDatasetOriginal = pd.read_csv(f'./A-Emotion-Data-Cleaning-Pipeline-for-Enhancing-Data-Reliability/data/csv_version/dev/emotion/allcharlinepairs-{fileTag}.csv')\n",
    "testDatasetOriginal = pd.read_csv(f'./A-Emotion-Data-Cleaning-Pipeline-for-Enhancing-Data-Reliability/data/csv_version/test/emotion/allcharlinepairs-{fileTag}.csv')\n",
    "trainDatasetOriginal = pd.concat([trainDatasetOriginal, testDatasetOriginal]).reset_index(drop=True) # shuffle and combine everything, ratio issue fix here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qESyVa_3pGvI",
    "outputId": "524b0586-0306-4f4f-d7fe-1deac6dcace6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A-Emotion-Data-Cleaning-Pipeline-for-Enhancing-Data-Reliability  sample_data\n",
      "drive\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "EJwu1Swr4iSM",
    "outputId": "75757382-cae1-4447-db62-b7e0cfc8b999"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-82accb85-e98a-4199-8e9d-3ea7564c8d5f\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>storyid</th>\n",
       "      <th>linenum</th>\n",
       "      <th>char</th>\n",
       "      <th>emotionworkerid</th>\n",
       "      <th>context</th>\n",
       "      <th>sentence</th>\n",
       "      <th>affected</th>\n",
       "      <th>emotion</th>\n",
       "      <th>plutchik</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>a2ddbb50-e45b-4ad3-becf-b2d8475172bf</td>\n",
       "      <td>1</td>\n",
       "      <td>I (myself)</td>\n",
       "      <td>ann0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I began making fish curry for my boyfriend and I.</td>\n",
       "      <td>yes</td>\n",
       "      <td>['Joy and excited to be making the food', 'con...</td>\n",
       "      <td>{'joy': 1, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>a2ddbb50-e45b-4ad3-becf-b2d8475172bf</td>\n",
       "      <td>2</td>\n",
       "      <td>I (myself)</td>\n",
       "      <td>ann0</td>\n",
       "      <td>I began making fish curry for my boyfriend and I.</td>\n",
       "      <td>I decided not to read a recipe since I've made...</td>\n",
       "      <td>yes</td>\n",
       "      <td>[\"I decided not to read a recipe since I've ma...</td>\n",
       "      <td>{'joy': 1, 'trust': 2, 'fear': 0, 'surprise': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>a2ddbb50-e45b-4ad3-becf-b2d8475172bf</td>\n",
       "      <td>3</td>\n",
       "      <td>I (myself)</td>\n",
       "      <td>ann0</td>\n",
       "      <td>I began making fish curry for my boyfriend and...</td>\n",
       "      <td>I let the curry sit before tasting.</td>\n",
       "      <td>yes</td>\n",
       "      <td>['anxious', 'confident', 'positive', 'none']</td>\n",
       "      <td>{'joy': 1, 'trust': 1, 'fear': 0, 'surprise': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>a2ddbb50-e45b-4ad3-becf-b2d8475172bf</td>\n",
       "      <td>4</td>\n",
       "      <td>I (myself)</td>\n",
       "      <td>ann0</td>\n",
       "      <td>I began making fish curry for my boyfriend and...</td>\n",
       "      <td>When it was time to taste, I was disgusted.</td>\n",
       "      <td>yes</td>\n",
       "      <td>['When it was time to taste', 'I was disgusted...</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 1, 'surprise': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>a2ddbb50-e45b-4ad3-becf-b2d8475172bf</td>\n",
       "      <td>5</td>\n",
       "      <td>I (myself)</td>\n",
       "      <td>ann0</td>\n",
       "      <td>I began making fish curry for my boyfriend and...</td>\n",
       "      <td>I accidentally used a whole garlic instead of ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>['I accidentally used a whole garlic instead o...</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24260</th>\n",
       "      <td>11845</td>\n",
       "      <td>9b53627e-41e5-47e6-9c6c-74d485572958</td>\n",
       "      <td>1</td>\n",
       "      <td>Rosemary</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rosemary was eating a snack.</td>\n",
       "      <td>no</td>\n",
       "      <td>['none']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24261</th>\n",
       "      <td>11846</td>\n",
       "      <td>9b53627e-41e5-47e6-9c6c-74d485572958</td>\n",
       "      <td>2</td>\n",
       "      <td>Rosemary</td>\n",
       "      <td>ann0</td>\n",
       "      <td>Rosemary was eating a snack.</td>\n",
       "      <td>She was at a party that had amazing food set out.</td>\n",
       "      <td>yes</td>\n",
       "      <td>['glad', 'satisfied', 'excited']</td>\n",
       "      <td>{'joy': 3, 'trust': 2, 'fear': 0, 'surprise': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24262</th>\n",
       "      <td>11847</td>\n",
       "      <td>9b53627e-41e5-47e6-9c6c-74d485572958</td>\n",
       "      <td>3</td>\n",
       "      <td>Rosemary</td>\n",
       "      <td>ann0</td>\n",
       "      <td>Rosemary was eating a snack.|She was at a part...</td>\n",
       "      <td>She had been dieting for weeks and was starving.</td>\n",
       "      <td>yes</td>\n",
       "      <td>['Agitated', 'deprived', 'famished']</td>\n",
       "      <td>{'joy': 1, 'trust': 1, 'fear': 0, 'surprise': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24263</th>\n",
       "      <td>11848</td>\n",
       "      <td>9b53627e-41e5-47e6-9c6c-74d485572958</td>\n",
       "      <td>4</td>\n",
       "      <td>Rosemary</td>\n",
       "      <td>ann0</td>\n",
       "      <td>Rosemary was eating a snack.|She was at a part...</td>\n",
       "      <td>After she stuffed herself, she regretted it.</td>\n",
       "      <td>yes</td>\n",
       "      <td>['gross', 'regret']</td>\n",
       "      <td>{'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24264</th>\n",
       "      <td>11849</td>\n",
       "      <td>9b53627e-41e5-47e6-9c6c-74d485572958</td>\n",
       "      <td>5</td>\n",
       "      <td>Rosemary</td>\n",
       "      <td>ann0</td>\n",
       "      <td>Rosemary was eating a snack.|She was at a part...</td>\n",
       "      <td>Rosemary swore to eat healthier tomorrow.</td>\n",
       "      <td>yes</td>\n",
       "      <td>['to continue dieting', 'ashamed']</td>\n",
       "      <td>{'joy': 2, 'trust': 2, 'fear': 0, 'surprise': ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24265 rows × 10 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82accb85-e98a-4199-8e9d-3ea7564c8d5f')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-82accb85-e98a-4199-8e9d-3ea7564c8d5f button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-82accb85-e98a-4199-8e9d-3ea7564c8d5f');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "       Unnamed: 0                               storyid  linenum        char  \\\n",
       "0               0  a2ddbb50-e45b-4ad3-becf-b2d8475172bf        1  I (myself)   \n",
       "1               1  a2ddbb50-e45b-4ad3-becf-b2d8475172bf        2  I (myself)   \n",
       "2               2  a2ddbb50-e45b-4ad3-becf-b2d8475172bf        3  I (myself)   \n",
       "3               3  a2ddbb50-e45b-4ad3-becf-b2d8475172bf        4  I (myself)   \n",
       "4               4  a2ddbb50-e45b-4ad3-becf-b2d8475172bf        5  I (myself)   \n",
       "...           ...                                   ...      ...         ...   \n",
       "24260       11845  9b53627e-41e5-47e6-9c6c-74d485572958        1    Rosemary   \n",
       "24261       11846  9b53627e-41e5-47e6-9c6c-74d485572958        2    Rosemary   \n",
       "24262       11847  9b53627e-41e5-47e6-9c6c-74d485572958        3    Rosemary   \n",
       "24263       11848  9b53627e-41e5-47e6-9c6c-74d485572958        4    Rosemary   \n",
       "24264       11849  9b53627e-41e5-47e6-9c6c-74d485572958        5    Rosemary   \n",
       "\n",
       "      emotionworkerid                                            context  \\\n",
       "0                ann0                                                NaN   \n",
       "1                ann0  I began making fish curry for my boyfriend and I.   \n",
       "2                ann0  I began making fish curry for my boyfriend and...   \n",
       "3                ann0  I began making fish curry for my boyfriend and...   \n",
       "4                ann0  I began making fish curry for my boyfriend and...   \n",
       "...               ...                                                ...   \n",
       "24260            none                                                NaN   \n",
       "24261            ann0                       Rosemary was eating a snack.   \n",
       "24262            ann0  Rosemary was eating a snack.|She was at a part...   \n",
       "24263            ann0  Rosemary was eating a snack.|She was at a part...   \n",
       "24264            ann0  Rosemary was eating a snack.|She was at a part...   \n",
       "\n",
       "                                                sentence affected  \\\n",
       "0      I began making fish curry for my boyfriend and I.      yes   \n",
       "1      I decided not to read a recipe since I've made...      yes   \n",
       "2                    I let the curry sit before tasting.      yes   \n",
       "3            When it was time to taste, I was disgusted.      yes   \n",
       "4      I accidentally used a whole garlic instead of ...      yes   \n",
       "...                                                  ...      ...   \n",
       "24260                       Rosemary was eating a snack.       no   \n",
       "24261  She was at a party that had amazing food set out.      yes   \n",
       "24262   She had been dieting for weeks and was starving.      yes   \n",
       "24263       After she stuffed herself, she regretted it.      yes   \n",
       "24264          Rosemary swore to eat healthier tomorrow.      yes   \n",
       "\n",
       "                                                 emotion  \\\n",
       "0      ['Joy and excited to be making the food', 'con...   \n",
       "1      [\"I decided not to read a recipe since I've ma...   \n",
       "2           ['anxious', 'confident', 'positive', 'none']   \n",
       "3      ['When it was time to taste', 'I was disgusted...   \n",
       "4      ['I accidentally used a whole garlic instead o...   \n",
       "...                                                  ...   \n",
       "24260                                           ['none']   \n",
       "24261                   ['glad', 'satisfied', 'excited']   \n",
       "24262               ['Agitated', 'deprived', 'famished']   \n",
       "24263                                ['gross', 'regret']   \n",
       "24264                 ['to continue dieting', 'ashamed']   \n",
       "\n",
       "                                                plutchik  \n",
       "0      {'joy': 1, 'trust': 0, 'fear': 0, 'surprise': ...  \n",
       "1      {'joy': 1, 'trust': 2, 'fear': 0, 'surprise': ...  \n",
       "2      {'joy': 1, 'trust': 1, 'fear': 0, 'surprise': ...  \n",
       "3      {'joy': 0, 'trust': 0, 'fear': 1, 'surprise': ...  \n",
       "4      {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...  \n",
       "...                                                  ...  \n",
       "24260  {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...  \n",
       "24261  {'joy': 3, 'trust': 2, 'fear': 0, 'surprise': ...  \n",
       "24262  {'joy': 1, 'trust': 1, 'fear': 0, 'surprise': ...  \n",
       "24263  {'joy': 0, 'trust': 0, 'fear': 0, 'surprise': ...  \n",
       "24264  {'joy': 2, 'trust': 2, 'fear': 0, 'surprise': ...  \n",
       "\n",
       "[24265 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDatasetOriginal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X3Ye-T454iSM"
   },
   "source": [
    "# Data preprocessing\n",
    "## As an example\n",
    "### input:\n",
    "Based on the following sentence <...>. The next sentence with the following emotion <...> should be\n",
    "### output\n",
    "<...>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "CiuZqHJb4iSN"
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import sng_parser\n",
    "def getKeyword(inputSentence):\n",
    "  graph = sng_parser.parse(inputSentence)\n",
    "  return (\", \".join((key.lower()).replace(\"a \", \"\").replace(\"the \", \"\").replace(\"an \", \"\")\n",
    "      for key in [x['span'] for x in graph['entities']])).replace(\"i,\", \"I,\")\n",
    "def parseRemapPlutchik(emotionList):\n",
    "    emotionListDict = ast.literal_eval(emotionList)\n",
    "    report = \"\"\n",
    "    for emoLabel in ['joy', 'trust', 'fear', 'surprise', 'sadness', 'disgust', 'anger', 'anticipation']:\n",
    "      report += \"\" if emotionListDict[emoLabel] == 0 else f\"{emoLabel}, \"\n",
    "    return report.strip(\", \")\n",
    "    \n",
    "def getPreviousSentenceWPrompt(inputDf):\n",
    "    generalEntity = \"it\"\n",
    "    previousSentenceFilter = inputDf[[True if index != len(inputDf['linenum'])-1 and inputDf.iloc[index]['linenum'] < inputDf.iloc[index+1]['linenum'] else False for index, linenum in enumerate(inputDf['linenum'])]] # remove last sentence of each story\n",
    "    nextEmotionFilter = inputDf[[True if index != 0 and inputDf.iloc[index]['linenum'] > inputDf.iloc[index-1]['linenum'] else False for index, linenum in enumerate(inputDf['linenum'])]] # remove the first sentence of each story\n",
    "    return [(f\"Generate next sentence that makes reader feels {parseRemapPlutchik(nextEmotion[1]['plutchik'])}.\"\n",
    "        +f\"<extra_id_0>KEYWORD: {getKeyword(nextEmotion[1]['sentence'])}\"\n",
    "        +f\"<extra_id_1>CONTEXT: {nextEmotion[1]['context'].replace('|', '')}\")\n",
    "        for previousSentence, nextEmotion in zip(previousSentenceFilter.iterrows(), nextEmotionFilter.iterrows())]\n",
    "\n",
    "def getNextSentence(inputDf):\n",
    "    return inputDf[[True if index != 0 and inputDf.iloc[index]['linenum'] > inputDf.iloc[index-1]['linenum'] else False for index, linenum in enumerate(inputDf['linenum'])]]['sentence']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_dDzK4p_4iSO"
   },
   "outputs": [],
   "source": [
    "processedDataTrain = DataFrame({'question': getPreviousSentenceWPrompt(trainDatasetOriginal), \"answer\":getNextSentence(trainDatasetOriginal)}).reset_index(drop=True)\n",
    "processedDataTest = DataFrame({'question': getPreviousSentenceWPrompt(testDatasetOriginal), \"answer\":getNextSentence(testDatasetOriginal)}).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YxBgSOn74uti"
   },
   "outputs": [],
   "source": [
    "processedDataTest\n",
    "processedDataTest.style.set_properties(subset=['question'], **{'width-min': '300px'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1-toW-Ra4iSO"
   },
   "outputs": [],
   "source": [
    "processedDataTrain.to_csv(f'./genV2-{fileTag}-train.csv', index=False)\n",
    "processedDataTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "uxHYYN-f4iSO",
    "outputId": "92d629b1-c3fa-4488-b107-c92ccefb133f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-68470a9d-223f-4c7c-9e8a-402c5172428e\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Generate next sentence that makes reader feels...</td>\n",
       "      <td>He dropped one on the floor by accident.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Generate next sentence that makes reader feels...</td>\n",
       "      <td>As a joke he pretended that it was a soccer ball.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Generate next sentence that makes reader feels...</td>\n",
       "      <td>He kicked the orange across the kitchen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Generate next sentence that makes reader feels...</td>\n",
       "      <td>It landed in a pot and he cheered!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Generate next sentence that makes reader feels...</td>\n",
       "      <td>She had been preparing for hours.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9475</th>\n",
       "      <td>Generate next sentence that makes reader feels...</td>\n",
       "      <td>Carol had to move around in the dark.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9476</th>\n",
       "      <td>Generate next sentence that makes reader feels...</td>\n",
       "      <td>She was at a party that had amazing food set out.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9477</th>\n",
       "      <td>Generate next sentence that makes reader feels...</td>\n",
       "      <td>She had been dieting for weeks and was starving.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9478</th>\n",
       "      <td>Generate next sentence that makes reader feels...</td>\n",
       "      <td>After she stuffed herself, she regretted it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9479</th>\n",
       "      <td>Generate next sentence that makes reader feels...</td>\n",
       "      <td>Rosemary swore to eat healthier tomorrow.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9480 rows × 2 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-68470a9d-223f-4c7c-9e8a-402c5172428e')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-68470a9d-223f-4c7c-9e8a-402c5172428e button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-68470a9d-223f-4c7c-9e8a-402c5172428e');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                               question  \\\n",
       "0     Generate next sentence that makes reader feels...   \n",
       "1     Generate next sentence that makes reader feels...   \n",
       "2     Generate next sentence that makes reader feels...   \n",
       "3     Generate next sentence that makes reader feels...   \n",
       "4     Generate next sentence that makes reader feels...   \n",
       "...                                                 ...   \n",
       "9475  Generate next sentence that makes reader feels...   \n",
       "9476  Generate next sentence that makes reader feels...   \n",
       "9477  Generate next sentence that makes reader feels...   \n",
       "9478  Generate next sentence that makes reader feels...   \n",
       "9479  Generate next sentence that makes reader feels...   \n",
       "\n",
       "                                                 answer  \n",
       "0              He dropped one on the floor by accident.  \n",
       "1     As a joke he pretended that it was a soccer ball.  \n",
       "2              He kicked the orange across the kitchen.  \n",
       "3                    It landed in a pot and he cheered!  \n",
       "4                     She had been preparing for hours.  \n",
       "...                                                 ...  \n",
       "9475              Carol had to move around in the dark.  \n",
       "9476  She was at a party that had amazing food set out.  \n",
       "9477   She had been dieting for weeks and was starving.  \n",
       "9478       After she stuffed herself, she regretted it.  \n",
       "9479          Rosemary swore to eat healthier tomorrow.  \n",
       "\n",
       "[9480 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processedDataTest.to_csv(f'./genV2-{fileTag}-test.csv', index=False)\n",
    "processedDataTest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GZnNTWDr4iSP"
   },
   "source": [
    "# Start Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "y6nEben93JAk"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dfTrain = pd.read_csv(f'./genV2-{fileTag}-train.csv')\n",
    "dfTest = pd.read_csv(f'./genV2-{fileTag}-test.csv')\n",
    "dfAll = pd.concat([dfTest, dfTrain]).sample(frac=1).reset_index(drop=True) # shuffle and combine everything, ratio issue fix here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "Suxgy7wC4IqL",
    "outputId": "7c523848-1211-4b5a-fe9e-4e6808a14661"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-c5797147-e118-4aa8-9f33-ca8b16418f72\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Generate next sentence that makes reader feels...</td>\n",
       "      <td>My little sister started swinging her net at t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Generate next sentence that makes reader feels...</td>\n",
       "      <td>Sadly, she cannot drink Diet Coke while pregnant.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Generate next sentence that makes reader feels...</td>\n",
       "      <td>The kids loved it, to her shock!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Generate next sentence that makes reader feels...</td>\n",
       "      <td>One day he and a friend blew up their lab.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Generate next sentence that makes reader feels...</td>\n",
       "      <td>He ordered a fancy new king size bed online.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28887</th>\n",
       "      <td>Generate next sentence that makes reader feels...</td>\n",
       "      <td>Then I tried 75 pounds.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28888</th>\n",
       "      <td>Generate next sentence that makes reader feels...</td>\n",
       "      <td>Cathy was so excited that she would be teachin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28889</th>\n",
       "      <td>Generate next sentence that makes reader feels...</td>\n",
       "      <td>We met on the playground while our parents pic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28890</th>\n",
       "      <td>Generate next sentence that makes reader feels...</td>\n",
       "      <td>Alas, there was a hole in the suit.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28891</th>\n",
       "      <td>Generate next sentence that makes reader feels...</td>\n",
       "      <td>When I got home, I couldn't find my cell phone.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28892 rows × 2 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c5797147-e118-4aa8-9f33-ca8b16418f72')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-c5797147-e118-4aa8-9f33-ca8b16418f72 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-c5797147-e118-4aa8-9f33-ca8b16418f72');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                question  \\\n",
       "0      Generate next sentence that makes reader feels...   \n",
       "1      Generate next sentence that makes reader feels...   \n",
       "2      Generate next sentence that makes reader feels...   \n",
       "3      Generate next sentence that makes reader feels...   \n",
       "4      Generate next sentence that makes reader feels...   \n",
       "...                                                  ...   \n",
       "28887  Generate next sentence that makes reader feels...   \n",
       "28888  Generate next sentence that makes reader feels...   \n",
       "28889  Generate next sentence that makes reader feels...   \n",
       "28890  Generate next sentence that makes reader feels...   \n",
       "28891  Generate next sentence that makes reader feels...   \n",
       "\n",
       "                                                  answer  \n",
       "0      My little sister started swinging her net at t...  \n",
       "1      Sadly, she cannot drink Diet Coke while pregnant.  \n",
       "2                       The kids loved it, to her shock!  \n",
       "3             One day he and a friend blew up their lab.  \n",
       "4           He ordered a fancy new king size bed online.  \n",
       "...                                                  ...  \n",
       "28887                            Then I tried 75 pounds.  \n",
       "28888  Cathy was so excited that she would be teachin...  \n",
       "28889  We met on the playground while our parents pic...  \n",
       "28890                Alas, there was a hole in the suit.  \n",
       "28891    When I got home, I couldn't find my cell phone.  \n",
       "\n",
       "[28892 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "wB441x104K-o"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "refer to Shivanand Roy 的visualization code，\n",
    "visualize dataframe，optional\n",
    "\"\"\"\n",
    "\n",
    "# Importing libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import os\n",
    "\n",
    "# Importing the T5 modules from huggingface/transformers\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "from rich.table import Column, Table\n",
    "from rich import box\n",
    "from rich.console import Console\n",
    "\n",
    "# define a rich console logger\n",
    "console=Console(record=True)\n",
    "\n",
    "def display_df(df):\n",
    "    \"\"\"\n",
    "    display dataframe in ASCII format\n",
    "    \"\"\"\n",
    "\n",
    "    console=Console() \n",
    "    table = Table(Column(\"source_text (Question)\", justify=\"center\" ), Column(\"target_text (Answer)\", justify=\"center\"), title=\"Sample Data\",pad_edge=False, box=box.ASCII)\n",
    "\n",
    "    for i, row in enumerate(df.values.tolist()):\n",
    "        table.add_row(row[0], row[1])\n",
    "\n",
    "    console.print(table)\n",
    "\n",
    "\n",
    "training_logger = Table(Column(\"Epoch\", justify=\"center\" ), \n",
    "             Column(\"Steps\", justify=\"center\"),\n",
    "             Column(\"Loss\", justify=\"center\"), \n",
    "             title=\"Training Status\",pad_edge=False, box=box.ASCII)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "tlYaKW9h4ai_"
   },
   "outputs": [],
   "source": [
    "# Setting up the device for GPU usage\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "8vLQPGAn4v17"
   },
   "outputs": [],
   "source": [
    "class NextSentenceDataSetClass(Dataset):\n",
    "  \"\"\"\n",
    "  Creating a custom dataset for reading the dataset and \n",
    "  loading it into the dataloader to pass it to the neural network for finetuning the model\n",
    "\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, dataframe, tokenizer, source_len, target_len, source_text, target_text):\n",
    "      self.tokenizer = tokenizer\n",
    "      self.data = dataframe\n",
    "      self.source_len = source_len\n",
    "      self.summ_len = target_len\n",
    "      self.target_text = self.data[target_text]\n",
    "      self.source_text = self.data[source_text]\n",
    "\n",
    "  def __len__(self):\n",
    "      return len(self.target_text)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "      source_text = str(self.source_text[index])\n",
    "      target_text = str(self.target_text[index])\n",
    "\n",
    "      #cleaning data so as to ensure data is in string type\n",
    "      source_text = ' '.join(source_text.split())\n",
    "      target_text = ' '.join(target_text.split())\n",
    "\n",
    "      source = self.tokenizer.batch_encode_plus([source_text], max_length= self.source_len, pad_to_max_length=True, truncation=True, padding=\"max_length\", return_tensors='pt')\n",
    "      target = self.tokenizer.batch_encode_plus([target_text], max_length= self.summ_len, pad_to_max_length=True, truncation=True, padding=\"max_length\", return_tensors='pt')\n",
    "\n",
    "      source_ids = source['input_ids'].squeeze()\n",
    "      source_mask = source['attention_mask'].squeeze()\n",
    "      target_ids = target['input_ids'].squeeze()\n",
    "      target_mask = target['attention_mask'].squeeze()\n",
    "\n",
    "      return {\n",
    "          'source_ids': source_ids.to(dtype=torch.long), \n",
    "          'source_mask': source_mask.to(dtype=torch.long), \n",
    "          'target_ids': target_ids.to(dtype=torch.long),\n",
    "          'target_ids_y': target_ids.to(dtype=torch.long)\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Nkj6wIMt40RK"
   },
   "outputs": [],
   "source": [
    "def train(epoch, tokenizer, model, device, loader, optimizer):\n",
    "  \"\"\"\n",
    "  Function to be called for training with the parameters passed from main function\n",
    "\n",
    "  \"\"\"\n",
    "\n",
    "  model.train()\n",
    "  for _,data in enumerate(loader, 0):\n",
    "    y = data['target_ids'].to(device, dtype = torch.long)\n",
    "    y_ids = y[:, :-1].contiguous()\n",
    "    lm_labels = y[:, 1:].clone().detach()\n",
    "    lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n",
    "    ids = data['source_ids'].to(device, dtype = torch.long)\n",
    "    mask = data['source_mask'].to(device, dtype = torch.long)\n",
    "\n",
    "    outputs = model(input_ids = ids, attention_mask = mask, decoder_input_ids=y_ids, labels=lm_labels)\n",
    "    loss = outputs[0]\n",
    "\n",
    "    if _%1000==0:\n",
    "        training_logger.add_row(str(epoch), str(_), str(loss))\n",
    "        console.print(training_logger)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "GUBykK-A43DF"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "bleu = []\n",
    "def validate(epoch, tokenizer, model, device, loader):\n",
    "  \"\"\"\n",
    "  Function to evaluate model for predictions\n",
    "\n",
    "  \"\"\"\n",
    "  model.eval()\n",
    "  predictions = []\n",
    "  actuals = []\n",
    "  with torch.no_grad():\n",
    "    for _, data in enumerate(loader, 0):\n",
    "      y = data['target_ids'].to(device, dtype = torch.long)\n",
    "      ids = data['source_ids'].to(device, dtype = torch.long)\n",
    "      mask = data['source_mask'].to(device, dtype = torch.long)\n",
    "\n",
    "      # generated_ids = model.generate(\n",
    "      #     input_ids = ids,\n",
    "      #     attention_mask = mask, \n",
    "      #     max_length=150, \n",
    "      #     num_beams=2,\n",
    "      #     repetition_penalty=2.5, \n",
    "      #     length_penalty=1.0, \n",
    "      #     early_stopping=True\n",
    "      # )\n",
    "      generated_ids = model.generate( \n",
    "                input_ids = ids, \n",
    "                attention_mask = mask, \n",
    "                max_length=150, \n",
    "                top_k=3, \n",
    "                repetition_penalty=2.5,\n",
    "                length_penalty=1.0, \n",
    "                early_stopping=True)\n",
    "      preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
    "      target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)for t in y]\n",
    "      BLEUscore = nltk.translate.bleu_score.sentence_bleu(target, preds)\n",
    "      if _%10==0:\n",
    "          console.print(f'Completed {_}')\n",
    "\n",
    "      predictions.extend(preds)\n",
    "      actuals.extend(target)\n",
    "      bleu.append(BLEUscore)\n",
    "  return predictions, actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Tw4RW_qO4_8T"
   },
   "outputs": [],
   "source": [
    "def T5Trainer(dataframe, source_text, target_text, model_params, output_dir=\"./outputs/\" ):  \n",
    "    \"\"\"\n",
    "    T5 trainer\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Set random seeds and deterministic pytorch for reproducibility\n",
    "    torch.manual_seed(model_params[\"SEED\"]) # pytorch random seed\n",
    "    np.random.seed(model_params[\"SEED\"]) # numpy random seed\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    # logging\n",
    "    console.log(f\"\"\"[Model]: Loading {model_params[\"MODEL\"]}...\\n\"\"\")\n",
    "\n",
    "    # tokenzier for encoding the text\n",
    "    tokenizer = T5Tokenizer.from_pretrained(model_params[\"MODEL\"])\n",
    "\n",
    "    # Defining the model. We are using t5-base model and added a Language model layer on top for generation of Summary. \n",
    "    # Further this model is sent to device (GPU/TPU) for using the hardware.\n",
    "    model = T5ForConditionalGeneration.from_pretrained(model_params[\"MODEL\"])\n",
    "    model = model.to(device)\n",
    "\n",
    "    # logging\n",
    "    console.log(f\"[Data]: Reading data...\\n\")\n",
    "\n",
    "    # Importing the raw dataset\n",
    "    dataframe = dataframe[[source_text,target_text]]\n",
    "    display_df(dataframe.head(2))\n",
    "\n",
    "\n",
    "    \"\"\" !!!ATTENTION PART!!!\"\"\"\n",
    "    # Creation of Dataset and Dataloader\n",
    "    # Defining the train size. So 80% of the data will be used for training and the rest for validation. \n",
    "    train_size = 1\n",
    "    train_dataset=dataframe.sample(frac=train_size,random_state = model_params[\"SEED\"])\n",
    "    val_dataset=dataframe.drop(train_dataset.index).reset_index(drop=True)\n",
    "    train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "    console.print(f\"FULL Dataset: {dataframe.shape}\")\n",
    "    console.print(f\"TRAIN Dataset: {train_dataset.shape}\")\n",
    "    console.print(f\"TEST Dataset: {val_dataset.shape}\\n\")\n",
    "\n",
    "\n",
    "    # Creating the Training and Validation dataset for further creation of Dataloader\n",
    "    training_set = NextSentenceDataSetClass(train_dataset, tokenizer, model_params[\"MAX_SOURCE_TEXT_LENGTH\"], model_params[\"MAX_TARGET_TEXT_LENGTH\"], source_text, target_text)\n",
    "    val_set = NextSentenceDataSetClass(val_dataset, tokenizer, model_params[\"MAX_SOURCE_TEXT_LENGTH\"], model_params[\"MAX_TARGET_TEXT_LENGTH\"], source_text, target_text)\n",
    "\n",
    "\n",
    "    # Defining the parameters for creation of dataloaders\n",
    "    train_params = {\n",
    "        'batch_size': model_params[\"TRAIN_BATCH_SIZE\"],\n",
    "        'shuffle': True,\n",
    "        'num_workers': 0\n",
    "        }\n",
    "\n",
    "\n",
    "    val_params = {\n",
    "        'batch_size': model_params[\"VALID_BATCH_SIZE\"],\n",
    "        'shuffle': False,\n",
    "        'num_workers': 0\n",
    "        }\n",
    "\n",
    "\n",
    "    # Creation of Dataloaders for testing and validation. This will be used down for training and validation stage for the model.\n",
    "    training_loader = DataLoader(training_set, **train_params)\n",
    "    val_loader = DataLoader(val_set, **val_params)\n",
    "\n",
    "\n",
    "    # Defining the optimizer that will be used to tune the weights of the network in the training session. \n",
    "    optimizer = torch.optim.Adam(params = model.parameters(), lr=model_params[\"LEARNING_RATE\"])\n",
    "\n",
    "\n",
    "    # Training loop\n",
    "    console.log(f'[Initiating Fine Tuning]...\\n')\n",
    "\n",
    "    for epoch in range(model_params[\"TRAIN_EPOCHS\"]):\n",
    "        train(epoch, tokenizer, model, device, training_loader, optimizer)\n",
    "      \n",
    "    # console.log(f\"[Saving Model]...\\n\")\n",
    "    #Saving the model after training\n",
    "    path = os.path.join(output_dir, \"model_files\")\n",
    "    model.save_pretrained(path)\n",
    "    tokenizer.save_pretrained(path)\n",
    "\n",
    "\n",
    "    # evaluating test dataset\n",
    "    console.log(f\"[Initiating Validation]...\\n\")\n",
    "    for epoch in range(model_params[\"VAL_EPOCHS\"]):\n",
    "        predictions, actuals = validate(epoch, tokenizer, model, device, val_loader)\n",
    "        final_df = pd.DataFrame({'Generated Text':predictions,'Actual Text':actuals})\n",
    "        final_df.to_csv(os.path.join(output_dir,'predictions.csv'))\n",
    "  \n",
    "    console.save_text(os.path.join(output_dir,'logs.txt'))\n",
    "\n",
    "    console.log(f\"[Validation Completed.]\\n\")\n",
    "    console.print(f\"\"\"[Model] Model saved @ {os.path.join(output_dir, \"model_files\")}\\n\"\"\")\n",
    "    console.print(f\"\"\"[Validation] Generation on Validation data saved @ {os.path.join(output_dir,'predictions.csv')}\\n\"\"\")\n",
    "    console.print(f\"\"\"[Logs] Logs saved @ {os.path.join(output_dir,'logs.txt')}\\n\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "PxCpQwD8PDIs"
   },
   "outputs": [],
   "source": [
    "model_params={\n",
    "  \"MODEL\": model_checkpoint,          # model_type: t5-base/t5-large\n",
    "  \"TRAIN_BATCH_SIZE\":batch_size,            # training batch size\n",
    "  \"VALID_BATCH_SIZE\":1,             # validation batch size\n",
    "  \"TRAIN_EPOCHS\":num_epochs,               # number of training epochs\n",
    "  \"VAL_EPOCHS\":1,                # number of validation epochs\n",
    "  \"LEARNING_RATE\":5e-4,             # learning rate\n",
    "  \"MAX_SOURCE_TEXT_LENGTH\":512,         # max length of source text\n",
    "  \"MAX_TARGET_TEXT_LENGTH\":50,          # max length of target text\n",
    "  \"SEED\": 42                  # set seed for reproducibility \n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OpXw6rj-5SI-",
    "outputId": "425c0d6d-3335-43ba-bb51-b0fd34a8fe22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Apr 23 02:52:10 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   31C    P0    50W / 400W |    717MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import locale\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "qijZoYeI55fM",
    "outputId": "bfecac0f-e20a-4c3d-fb7c-895146595a6a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03:01:22] </span><span style=\"font-weight: bold\">[</span>Model<span style=\"font-weight: bold\">]</span>: Loading mrm8488/t5-base-finetuned-common_gen<span style=\"color: #808000; text-decoration-color: #808000\">...</span>              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">&lt;ipython-input-11-91b2f7e68627&gt;:13</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                  </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[03:01:22]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mModel\u001b[1m]\u001b[0m: Loading mrm8488/t5-base-finetuned-common_gen\u001b[33m...\u001b[0m              \u001b[2m<ipython-input-11-91b2f7e68627>\u001b[0m\u001b[2m:\u001b[0m\u001b[2m13\u001b[0m\n",
       "\u001b[2;36m           \u001b[0m                                                                      \u001b[2m                                  \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03:01:27] </span><span style=\"font-weight: bold\">[</span>Data<span style=\"font-weight: bold\">]</span>: Reading data<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">&lt;ipython-input-11-91b2f7e68627&gt;:24</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                  </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[03:01:27]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mData\u001b[1m]\u001b[0m: Reading data\u001b[33m...\u001b[0m                                               \u001b[2m<ipython-input-11-91b2f7e68627>\u001b[0m\u001b[2m:\u001b[0m\u001b[2m24\u001b[0m\n",
       "\u001b[2;36m           \u001b[0m                                                                      \u001b[2m                                  \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                    Sample Data                                                    </span>\n",
       "+-----------------------------------------------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">                source_text (Question)                  </span>|<span style=\"font-weight: bold\">                  target_text (Answer)                  </span>|\n",
       "|--------------------------------------------------------+--------------------------------------------------------|\n",
       "|  Generate next sentence that makes reader feels joy,   |    My little sister started swinging her net at the    |\n",
       "| surprise, anticipation.&lt;extra_id_0&gt;KEYWORD: my little  |                      butterflies.                      |\n",
       "|  sister, her net, butterflies&lt;extra_id_1&gt;CONTEXT: My   |                                                        |\n",
       "|little sister wanted to catch a butterfly for a pet.She |                                                        |\n",
       "|had no idea what she was doing.I helped her build a net |                                                        |\n",
       "|             and showed her where to look.              |                                                        |\n",
       "|    Generate next sentence that makes reader feels      |    Sadly, she cannot drink Diet Coke while pregnant.   |\n",
       "|        sadness.&lt;extra_id_0&gt;KEYWORD: she, diet          |                                                        |\n",
       "|coke&lt;extra_id_1&gt;CONTEXT: Jenna loves Diet Coke.She and  |                                                        |\n",
       "|          her husband decide to have a baby.            |                                                        |\n",
       "+-----------------------------------------------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                                    Sample Data                                                    \u001b[0m\n",
       "+-----------------------------------------------------------------------------------------------------------------+\n",
       "|\u001b[1m                source_text (Question)                 \u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                 target_text (Answer)                  \u001b[0m|\n",
       "|--------------------------------------------------------+--------------------------------------------------------|\n",
       "|  Generate next sentence that makes reader feels joy,   |    My little sister started swinging her net at the    |\n",
       "| surprise, anticipation.<extra_id_0>KEYWORD: my little  |                      butterflies.                      |\n",
       "|  sister, her net, butterflies<extra_id_1>CONTEXT: My   |                                                        |\n",
       "|little sister wanted to catch a butterfly for a pet.She |                                                        |\n",
       "|had no idea what she was doing.I helped her build a net |                                                        |\n",
       "|             and showed her where to look.              |                                                        |\n",
       "|    Generate next sentence that makes reader feels      |    Sadly, she cannot drink Diet Coke while pregnant.   |\n",
       "|        sadness.<extra_id_0>KEYWORD: she, diet          |                                                        |\n",
       "|coke<extra_id_1>CONTEXT: Jenna loves Diet Coke.She and  |                                                        |\n",
       "|          her husband decide to have a baby.            |                                                        |\n",
       "+-----------------------------------------------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">FULL Dataset: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28892</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "FULL Dataset: \u001b[1m(\u001b[0m\u001b[1;36m28892\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">TRAIN Dataset: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28892</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "TRAIN Dataset: \u001b[1m(\u001b[0m\u001b[1;36m28892\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">TEST Dataset: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "TEST Dataset: \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"font-weight: bold\">[</span>Initiating Fine Tuning<span style=\"font-weight: bold\">]</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">&lt;ipython-input-11-91b2f7e68627&gt;:74</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                  </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mInitiating Fine Tuning\u001b[1m]\u001b[0m\u001b[33m...\u001b[0m                                           \u001b[2m<ipython-input-11-91b2f7e68627>\u001b[0m\u001b[2m:\u001b[0m\u001b[2m74\u001b[0m\n",
       "\u001b[2;36m           \u001b[0m                                                                      \u001b[2m                                  \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  7   |   0   | tensor(0.1782, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  7   |   0   | tensor(0.1782, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  7   |   0   | tensor(0.1782, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  7   | 1000  | tensor(0.2121, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  7   |   0   | tensor(0.1782, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  7   | 1000  | tensor(0.2121, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  7   |   0   | tensor(0.1782, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  7   | 1000  | tensor(0.2121, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  8   |   0   | tensor(0.1662, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  7   |   0   | tensor(0.1782, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  7   | 1000  | tensor(0.2121, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  8   |   0   | tensor(0.1662, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  7   |   0   | tensor(0.1782, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  7   | 1000  | tensor(0.2121, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  8   |   0   | tensor(0.1662, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  8   | 1000  | tensor(0.1162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  7   |   0   | tensor(0.1782, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  7   | 1000  | tensor(0.2121, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  8   |   0   | tensor(0.1662, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  8   | 1000  | tensor(0.1162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  7   |   0   | tensor(0.1782, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  7   | 1000  | tensor(0.2121, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  8   |   0   | tensor(0.1662, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  8   | 1000  | tensor(0.1162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  9   |   0   | tensor(0.1099, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  7   |   0   | tensor(0.1782, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  7   | 1000  | tensor(0.2121, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  8   |   0   | tensor(0.1662, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  8   | 1000  | tensor(0.1162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  9   |   0   | tensor(0.1099, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  7   |   0   | tensor(0.1782, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  7   | 1000  | tensor(0.2121, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  8   |   0   | tensor(0.1662, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  8   | 1000  | tensor(0.1162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  9   |   0   | tensor(0.1099, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  9   | 1000  | tensor(0.1202, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  7   |   0   | tensor(0.1782, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  7   | 1000  | tensor(0.2121, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  8   |   0   | tensor(0.1662, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  8   | 1000  | tensor(0.1162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  9   |   0   | tensor(0.1099, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  9   | 1000  | tensor(0.1202, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  7   |   0   | tensor(0.1782, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  7   | 1000  | tensor(0.2121, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  8   |   0   | tensor(0.1662, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  8   | 1000  | tensor(0.1162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  9   |   0   | tensor(0.1099, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  9   | 1000  | tensor(0.1202, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 10   |   0   | tensor(0.0628, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  7   |   0   | tensor(0.1782, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  7   | 1000  | tensor(0.2121, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  8   |   0   | tensor(0.1662, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  8   | 1000  | tensor(0.1162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  9   |   0   | tensor(0.1099, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  9   | 1000  | tensor(0.1202, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 10   |   0   | tensor(0.0628, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  7   |   0   | tensor(0.1782, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  7   | 1000  | tensor(0.2121, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  8   |   0   | tensor(0.1662, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  8   | 1000  | tensor(0.1162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  9   |   0   | tensor(0.1099, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  9   | 1000  | tensor(0.1202, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 10   |   0   | tensor(0.0628, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 10   | 1000  | tensor(0.2052, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  7   |   0   | tensor(0.1782, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  7   | 1000  | tensor(0.2121, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  8   |   0   | tensor(0.1662, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  8   | 1000  | tensor(0.1162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  9   |   0   | tensor(0.1099, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  9   | 1000  | tensor(0.1202, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 10   |   0   | tensor(0.0628, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 10   | 1000  | tensor(0.2052, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  7   |   0   | tensor(0.1782, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  7   | 1000  | tensor(0.2121, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  8   |   0   | tensor(0.1662, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  8   | 1000  | tensor(0.1162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  9   |   0   | tensor(0.1099, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  9   | 1000  | tensor(0.1202, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 10   |   0   | tensor(0.0628, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 10   | 1000  | tensor(0.2052, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 11   |   0   | tensor(0.0696, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  7   |   0   | tensor(0.1782, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  7   | 1000  | tensor(0.2121, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  8   |   0   | tensor(0.1662, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  8   | 1000  | tensor(0.1162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  9   |   0   | tensor(0.1099, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  9   | 1000  | tensor(0.1202, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 10   |   0   | tensor(0.0628, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 10   | 1000  | tensor(0.2052, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 11   |   0   | tensor(0.0696, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  7   |   0   | tensor(0.1782, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  7   | 1000  | tensor(0.2121, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  8   |   0   | tensor(0.1662, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  8   | 1000  | tensor(0.1162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  9   |   0   | tensor(0.1099, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  9   | 1000  | tensor(0.1202, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 10   |   0   | tensor(0.0628, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 10   | 1000  | tensor(0.2052, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 11   |   0   | tensor(0.0696, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 11   | 1000  | tensor(0.1324, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  7   |   0   | tensor(0.1782, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  7   | 1000  | tensor(0.2121, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  8   |   0   | tensor(0.1662, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  8   | 1000  | tensor(0.1162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  9   |   0   | tensor(0.1099, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  9   | 1000  | tensor(0.1202, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 10   |   0   | tensor(0.0628, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 10   | 1000  | tensor(0.2052, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 11   |   0   | tensor(0.0696, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 11   | 1000  | tensor(0.1324, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  7   |   0   | tensor(0.1782, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  7   | 1000  | tensor(0.2121, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  8   |   0   | tensor(0.1662, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  8   | 1000  | tensor(0.1162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  9   |   0   | tensor(0.1099, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  9   | 1000  | tensor(0.1202, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 10   |   0   | tensor(0.0628, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 10   | 1000  | tensor(0.2052, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 11   |   0   | tensor(0.0696, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 11   | 1000  | tensor(0.1324, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 12   |   0   | tensor(0.1483, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  7   |   0   | tensor(0.1782, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  7   | 1000  | tensor(0.2121, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  8   |   0   | tensor(0.1662, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  8   | 1000  | tensor(0.1162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  9   |   0   | tensor(0.1099, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  9   | 1000  | tensor(0.1202, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 10   |   0   | tensor(0.0628, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 10   | 1000  | tensor(0.2052, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 11   |   0   | tensor(0.0696, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 11   | 1000  | tensor(0.1324, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 12   |   0   | tensor(0.1483, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  7   |   0   | tensor(0.1782, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  7   | 1000  | tensor(0.2121, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  8   |   0   | tensor(0.1662, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  8   | 1000  | tensor(0.1162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  9   |   0   | tensor(0.1099, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  9   | 1000  | tensor(0.1202, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 10   |   0   | tensor(0.0628, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 10   | 1000  | tensor(0.2052, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 11   |   0   | tensor(0.0696, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 11   | 1000  | tensor(0.1324, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 12   |   0   | tensor(0.1483, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 12   | 1000  | tensor(0.1027, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  7   |   0   | tensor(0.1782, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  7   | 1000  | tensor(0.2121, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  8   |   0   | tensor(0.1662, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  8   | 1000  | tensor(0.1162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  9   |   0   | tensor(0.1099, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  9   | 1000  | tensor(0.1202, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 10   |   0   | tensor(0.0628, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 10   | 1000  | tensor(0.2052, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 11   |   0   | tensor(0.0696, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 11   | 1000  | tensor(0.1324, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 12   |   0   | tensor(0.1483, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 12   | 1000  | tensor(0.1027, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  7   |   0   | tensor(0.1782, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  7   | 1000  | tensor(0.2121, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  8   |   0   | tensor(0.1662, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  8   | 1000  | tensor(0.1162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  9   |   0   | tensor(0.1099, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  9   | 1000  | tensor(0.1202, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 10   |   0   | tensor(0.0628, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 10   | 1000  | tensor(0.2052, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 11   |   0   | tensor(0.0696, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 11   | 1000  | tensor(0.1324, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 12   |   0   | tensor(0.1483, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 12   | 1000  | tensor(0.1027, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 13   |   0   | tensor(0.1050, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  7   |   0   | tensor(0.1782, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  7   | 1000  | tensor(0.2121, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  8   |   0   | tensor(0.1662, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  8   | 1000  | tensor(0.1162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  9   |   0   | tensor(0.1099, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  9   | 1000  | tensor(0.1202, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 10   |   0   | tensor(0.0628, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 10   | 1000  | tensor(0.2052, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 11   |   0   | tensor(0.0696, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 11   | 1000  | tensor(0.1324, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 12   |   0   | tensor(0.1483, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 12   | 1000  | tensor(0.1027, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 13   |   0   | tensor(0.1050, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  7   |   0   | tensor(0.1782, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  7   | 1000  | tensor(0.2121, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  8   |   0   | tensor(0.1662, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  8   | 1000  | tensor(0.1162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  9   |   0   | tensor(0.1099, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  9   | 1000  | tensor(0.1202, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 10   |   0   | tensor(0.0628, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 10   | 1000  | tensor(0.2052, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 11   |   0   | tensor(0.0696, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 11   | 1000  | tensor(0.1324, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 12   |   0   | tensor(0.1483, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 12   | 1000  | tensor(0.1027, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 13   |   0   | tensor(0.1050, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 13   | 1000  | tensor(0.0867, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  7   |   0   | tensor(0.1782, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  7   | 1000  | tensor(0.2121, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  8   |   0   | tensor(0.1662, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  8   | 1000  | tensor(0.1162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  9   |   0   | tensor(0.1099, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  9   | 1000  | tensor(0.1202, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 10   |   0   | tensor(0.0628, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 10   | 1000  | tensor(0.2052, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 11   |   0   | tensor(0.0696, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 11   | 1000  | tensor(0.1324, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 12   |   0   | tensor(0.1483, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 12   | 1000  | tensor(0.1027, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 13   |   0   | tensor(0.1050, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 13   | 1000  | tensor(0.0867, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  7   |   0   | tensor(0.1782, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  7   | 1000  | tensor(0.2121, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  8   |   0   | tensor(0.1662, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  8   | 1000  | tensor(0.1162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  9   |   0   | tensor(0.1099, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  9   | 1000  | tensor(0.1202, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 10   |   0   | tensor(0.0628, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 10   | 1000  | tensor(0.2052, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 11   |   0   | tensor(0.0696, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 11   | 1000  | tensor(0.1324, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 12   |   0   | tensor(0.1483, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 12   | 1000  | tensor(0.1027, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 13   |   0   | tensor(0.1050, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 13   | 1000  | tensor(0.0867, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 14   |   0   | tensor(0.0529, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  7   |   0   | tensor(0.1782, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  7   | 1000  | tensor(0.2121, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  8   |   0   | tensor(0.1662, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  8   | 1000  | tensor(0.1162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  9   |   0   | tensor(0.1099, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  9   | 1000  | tensor(0.1202, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 10   |   0   | tensor(0.0628, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 10   | 1000  | tensor(0.2052, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 11   |   0   | tensor(0.0696, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 11   | 1000  | tensor(0.1324, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 12   |   0   | tensor(0.1483, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 12   | 1000  | tensor(0.1027, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 13   |   0   | tensor(0.1050, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 13   | 1000  | tensor(0.0867, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 14   |   0   | tensor(0.0529, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  7   |   0   | tensor(0.1782, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  7   | 1000  | tensor(0.2121, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  8   |   0   | tensor(0.1662, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  8   | 1000  | tensor(0.1162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  9   |   0   | tensor(0.1099, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  9   | 1000  | tensor(0.1202, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 10   |   0   | tensor(0.0628, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 10   | 1000  | tensor(0.2052, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 11   |   0   | tensor(0.0696, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 11   | 1000  | tensor(0.1324, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 12   |   0   | tensor(0.1483, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 12   | 1000  | tensor(0.1027, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 13   |   0   | tensor(0.1050, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 13   | 1000  | tensor(0.0867, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 14   |   0   | tensor(0.0529, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 14   | 1000  | tensor(0.0234, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  7   |   0   | tensor(0.1782, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  7   | 1000  | tensor(0.2121, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  8   |   0   | tensor(0.1662, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  8   | 1000  | tensor(0.1162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  9   |   0   | tensor(0.1099, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  9   | 1000  | tensor(0.1202, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 10   |   0   | tensor(0.0628, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 10   | 1000  | tensor(0.2052, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 11   |   0   | tensor(0.0696, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 11   | 1000  | tensor(0.1324, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 12   |   0   | tensor(0.1483, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 12   | 1000  | tensor(0.1027, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 13   |   0   | tensor(0.1050, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 13   | 1000  | tensor(0.0867, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 14   |   0   | tensor(0.0529, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 14   | 1000  | tensor(0.0234, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  7   |   0   | tensor(0.1782, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  7   | 1000  | tensor(0.2121, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  8   |   0   | tensor(0.1662, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  8   | 1000  | tensor(0.1162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  9   |   0   | tensor(0.1099, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  9   | 1000  | tensor(0.1202, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 10   |   0   | tensor(0.0628, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 10   | 1000  | tensor(0.2052, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 11   |   0   | tensor(0.0696, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 11   | 1000  | tensor(0.1324, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 12   |   0   | tensor(0.1483, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 12   | 1000  | tensor(0.1027, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 13   |   0   | tensor(0.1050, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 13   | 1000  | tensor(0.0867, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 14   |   0   | tensor(0.0529, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 14   | 1000  | tensor(0.0234, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 15   |   0   | tensor(0.0961, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  7   |   0   | tensor(0.1782, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  7   | 1000  | tensor(0.2121, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  8   |   0   | tensor(0.1662, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  8   | 1000  | tensor(0.1162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  9   |   0   | tensor(0.1099, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  9   | 1000  | tensor(0.1202, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 10   |   0   | tensor(0.0628, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 10   | 1000  | tensor(0.2052, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 11   |   0   | tensor(0.0696, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 11   | 1000  | tensor(0.1324, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 12   |   0   | tensor(0.1483, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 12   | 1000  | tensor(0.1027, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 13   |   0   | tensor(0.1050, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 13   | 1000  | tensor(0.0867, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 14   |   0   | tensor(0.0529, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 14   | 1000  | tensor(0.0234, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 15   |   0   | tensor(0.0961, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  7   |   0   | tensor(0.1782, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  7   | 1000  | tensor(0.2121, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  8   |   0   | tensor(0.1662, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  8   | 1000  | tensor(0.1162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  9   |   0   | tensor(0.1099, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  9   | 1000  | tensor(0.1202, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 10   |   0   | tensor(0.0628, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 10   | 1000  | tensor(0.2052, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 11   |   0   | tensor(0.0696, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 11   | 1000  | tensor(0.1324, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 12   |   0   | tensor(0.1483, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 12   | 1000  | tensor(0.1027, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 13   |   0   | tensor(0.1050, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 13   | 1000  | tensor(0.0867, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 14   |   0   | tensor(0.0529, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 14   | 1000  | tensor(0.0234, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 15   |   0   | tensor(0.0961, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 15   | 1000  | tensor(0.0514, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  7   |   0   | tensor(0.1782, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  7   | 1000  | tensor(0.2121, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  8   |   0   | tensor(0.1662, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  8   | 1000  | tensor(0.1162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  9   |   0   | tensor(0.1099, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  9   | 1000  | tensor(0.1202, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 10   |   0   | tensor(0.0628, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 10   | 1000  | tensor(0.2052, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 11   |   0   | tensor(0.0696, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 11   | 1000  | tensor(0.1324, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 12   |   0   | tensor(0.1483, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 12   | 1000  | tensor(0.1027, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 13   |   0   | tensor(0.1050, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 13   | 1000  | tensor(0.0867, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 14   |   0   | tensor(0.0529, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 14   | 1000  | tensor(0.0234, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 15   |   0   | tensor(0.0961, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 15   | 1000  | tensor(0.0514, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  7   |   0   | tensor(0.1782, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  7   | 1000  | tensor(0.2121, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  8   |   0   | tensor(0.1662, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  8   | 1000  | tensor(0.1162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  9   |   0   | tensor(0.1099, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  9   | 1000  | tensor(0.1202, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 10   |   0   | tensor(0.0628, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 10   | 1000  | tensor(0.2052, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 11   |   0   | tensor(0.0696, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 11   | 1000  | tensor(0.1324, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 12   |   0   | tensor(0.1483, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 12   | 1000  | tensor(0.1027, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 13   |   0   | tensor(0.1050, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 13   | 1000  | tensor(0.0867, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 14   |   0   | tensor(0.0529, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 14   | 1000  | tensor(0.0234, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 15   |   0   | tensor(0.0961, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 15   | 1000  | tensor(0.0514, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 16   |   0   | tensor(0.1698, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  7   |   0   | tensor(0.1782, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  7   | 1000  | tensor(0.2121, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  8   |   0   | tensor(0.1662, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  8   | 1000  | tensor(0.1162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  9   |   0   | tensor(0.1099, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  9   | 1000  | tensor(0.1202, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 10   |   0   | tensor(0.0628, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 10   | 1000  | tensor(0.2052, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 11   |   0   | tensor(0.0696, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 11   | 1000  | tensor(0.1324, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 12   |   0   | tensor(0.1483, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 12   | 1000  | tensor(0.1027, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 13   |   0   | tensor(0.1050, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 13   | 1000  | tensor(0.0867, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 14   |   0   | tensor(0.0529, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 14   | 1000  | tensor(0.0234, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 15   |   0   | tensor(0.0961, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 15   | 1000  | tensor(0.0514, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 16   |   0   | tensor(0.1698, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  7   |   0   | tensor(0.1782, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  7   | 1000  | tensor(0.2121, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  8   |   0   | tensor(0.1662, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  8   | 1000  | tensor(0.1162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  9   |   0   | tensor(0.1099, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  9   | 1000  | tensor(0.1202, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 10   |   0   | tensor(0.0628, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 10   | 1000  | tensor(0.2052, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 11   |   0   | tensor(0.0696, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 11   | 1000  | tensor(0.1324, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 12   |   0   | tensor(0.1483, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 12   | 1000  | tensor(0.1027, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 13   |   0   | tensor(0.1050, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 13   | 1000  | tensor(0.0867, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 14   |   0   | tensor(0.0529, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 14   | 1000  | tensor(0.0234, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 15   |   0   | tensor(0.0961, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 15   | 1000  | tensor(0.0514, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 16   |   0   | tensor(0.1698, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 16   | 1000  | tensor(0.0525, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  7   |   0   | tensor(0.1782, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  7   | 1000  | tensor(0.2121, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  8   |   0   | tensor(0.1662, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  8   | 1000  | tensor(0.1162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  9   |   0   | tensor(0.1099, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  9   | 1000  | tensor(0.1202, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 10   |   0   | tensor(0.0628, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 10   | 1000  | tensor(0.2052, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 11   |   0   | tensor(0.0696, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 11   | 1000  | tensor(0.1324, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 12   |   0   | tensor(0.1483, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 12   | 1000  | tensor(0.1027, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 13   |   0   | tensor(0.1050, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 13   | 1000  | tensor(0.0867, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 14   |   0   | tensor(0.0529, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 14   | 1000  | tensor(0.0234, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 15   |   0   | tensor(0.0961, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 15   | 1000  | tensor(0.0514, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 16   |   0   | tensor(0.1698, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 16   | 1000  | tensor(0.0525, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  7   |   0   | tensor(0.1782, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  7   | 1000  | tensor(0.2121, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  8   |   0   | tensor(0.1662, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  8   | 1000  | tensor(0.1162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  9   |   0   | tensor(0.1099, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  9   | 1000  | tensor(0.1202, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 10   |   0   | tensor(0.0628, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 10   | 1000  | tensor(0.2052, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 11   |   0   | tensor(0.0696, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 11   | 1000  | tensor(0.1324, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 12   |   0   | tensor(0.1483, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 12   | 1000  | tensor(0.1027, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 13   |   0   | tensor(0.1050, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 13   | 1000  | tensor(0.0867, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 14   |   0   | tensor(0.0529, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 14   | 1000  | tensor(0.0234, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 15   |   0   | tensor(0.0961, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 15   | 1000  | tensor(0.0514, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 16   |   0   | tensor(0.1698, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 16   | 1000  | tensor(0.0525, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 17   |   0   | tensor(0.0791, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  7   |   0   | tensor(0.1782, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  7   | 1000  | tensor(0.2121, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  8   |   0   | tensor(0.1662, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  8   | 1000  | tensor(0.1162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  9   |   0   | tensor(0.1099, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  9   | 1000  | tensor(0.1202, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 10   |   0   | tensor(0.0628, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 10   | 1000  | tensor(0.2052, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 11   |   0   | tensor(0.0696, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 11   | 1000  | tensor(0.1324, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 12   |   0   | tensor(0.1483, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 12   | 1000  | tensor(0.1027, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 13   |   0   | tensor(0.1050, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 13   | 1000  | tensor(0.0867, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 14   |   0   | tensor(0.0529, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 14   | 1000  | tensor(0.0234, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 15   |   0   | tensor(0.0961, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 15   | 1000  | tensor(0.0514, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 16   |   0   | tensor(0.1698, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 16   | 1000  | tensor(0.0525, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 17   |   0   | tensor(0.0791, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  7   |   0   | tensor(0.1782, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  7   | 1000  | tensor(0.2121, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  8   |   0   | tensor(0.1662, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  8   | 1000  | tensor(0.1162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  9   |   0   | tensor(0.1099, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  9   | 1000  | tensor(0.1202, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 10   |   0   | tensor(0.0628, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 10   | 1000  | tensor(0.2052, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 11   |   0   | tensor(0.0696, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 11   | 1000  | tensor(0.1324, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 12   |   0   | tensor(0.1483, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 12   | 1000  | tensor(0.1027, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 13   |   0   | tensor(0.1050, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 13   | 1000  | tensor(0.0867, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 14   |   0   | tensor(0.0529, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 14   | 1000  | tensor(0.0234, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 15   |   0   | tensor(0.0961, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 15   | 1000  | tensor(0.0514, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 16   |   0   | tensor(0.1698, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 16   | 1000  | tensor(0.0525, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 17   |   0   | tensor(0.0791, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 17   | 1000  | tensor(0.0678, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  7   |   0   | tensor(0.1782, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  7   | 1000  | tensor(0.2121, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  8   |   0   | tensor(0.1662, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  8   | 1000  | tensor(0.1162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  9   |   0   | tensor(0.1099, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  9   | 1000  | tensor(0.1202, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 10   |   0   | tensor(0.0628, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 10   | 1000  | tensor(0.2052, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 11   |   0   | tensor(0.0696, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 11   | 1000  | tensor(0.1324, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 12   |   0   | tensor(0.1483, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 12   | 1000  | tensor(0.1027, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 13   |   0   | tensor(0.1050, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 13   | 1000  | tensor(0.0867, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 14   |   0   | tensor(0.0529, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 14   | 1000  | tensor(0.0234, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 15   |   0   | tensor(0.0961, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 15   | 1000  | tensor(0.0514, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 16   |   0   | tensor(0.1698, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 16   | 1000  | tensor(0.0525, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 17   |   0   | tensor(0.0791, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 17   | 1000  | tensor(0.0678, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  7   |   0   | tensor(0.1782, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  7   | 1000  | tensor(0.2121, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  8   |   0   | tensor(0.1662, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  8   | 1000  | tensor(0.1162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  9   |   0   | tensor(0.1099, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  9   | 1000  | tensor(0.1202, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 10   |   0   | tensor(0.0628, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 10   | 1000  | tensor(0.2052, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 11   |   0   | tensor(0.0696, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 11   | 1000  | tensor(0.1324, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 12   |   0   | tensor(0.1483, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 12   | 1000  | tensor(0.1027, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 13   |   0   | tensor(0.1050, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 13   | 1000  | tensor(0.0867, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 14   |   0   | tensor(0.0529, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 14   | 1000  | tensor(0.0234, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 15   |   0   | tensor(0.0961, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 15   | 1000  | tensor(0.0514, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 16   |   0   | tensor(0.1698, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 16   | 1000  | tensor(0.0525, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 17   |   0   | tensor(0.0791, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 17   | 1000  | tensor(0.0678, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 18   |   0   | tensor(0.0377, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  7   |   0   | tensor(0.1782, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  7   | 1000  | tensor(0.2121, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  8   |   0   | tensor(0.1662, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  8   | 1000  | tensor(0.1162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  9   |   0   | tensor(0.1099, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  9   | 1000  | tensor(0.1202, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 10   |   0   | tensor(0.0628, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 10   | 1000  | tensor(0.2052, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 11   |   0   | tensor(0.0696, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 11   | 1000  | tensor(0.1324, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 12   |   0   | tensor(0.1483, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 12   | 1000  | tensor(0.1027, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 13   |   0   | tensor(0.1050, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 13   | 1000  | tensor(0.0867, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 14   |   0   | tensor(0.0529, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 14   | 1000  | tensor(0.0234, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 15   |   0   | tensor(0.0961, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 15   | 1000  | tensor(0.0514, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 16   |   0   | tensor(0.1698, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 16   | 1000  | tensor(0.0525, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 17   |   0   | tensor(0.0791, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 17   | 1000  | tensor(0.0678, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 18   |   0   | tensor(0.0377, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  7   |   0   | tensor(0.1782, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  7   | 1000  | tensor(0.2121, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  8   |   0   | tensor(0.1662, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  8   | 1000  | tensor(0.1162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  9   |   0   | tensor(0.1099, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  9   | 1000  | tensor(0.1202, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 10   |   0   | tensor(0.0628, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 10   | 1000  | tensor(0.2052, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 11   |   0   | tensor(0.0696, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 11   | 1000  | tensor(0.1324, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 12   |   0   | tensor(0.1483, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 12   | 1000  | tensor(0.1027, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 13   |   0   | tensor(0.1050, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 13   | 1000  | tensor(0.0867, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 14   |   0   | tensor(0.0529, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 14   | 1000  | tensor(0.0234, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 15   |   0   | tensor(0.0961, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 15   | 1000  | tensor(0.0514, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 16   |   0   | tensor(0.1698, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 16   | 1000  | tensor(0.0525, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 17   |   0   | tensor(0.0791, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 17   | 1000  | tensor(0.0678, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 18   |   0   | tensor(0.0377, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 18   | 1000  | tensor(0.1031, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  7   |   0   | tensor(0.1782, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  7   | 1000  | tensor(0.2121, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  8   |   0   | tensor(0.1662, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  8   | 1000  | tensor(0.1162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  9   |   0   | tensor(0.1099, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  9   | 1000  | tensor(0.1202, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 10   |   0   | tensor(0.0628, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 10   | 1000  | tensor(0.2052, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 11   |   0   | tensor(0.0696, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 11   | 1000  | tensor(0.1324, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 12   |   0   | tensor(0.1483, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 12   | 1000  | tensor(0.1027, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 13   |   0   | tensor(0.1050, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 13   | 1000  | tensor(0.0867, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 14   |   0   | tensor(0.0529, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 14   | 1000  | tensor(0.0234, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 15   |   0   | tensor(0.0961, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 15   | 1000  | tensor(0.0514, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 16   |   0   | tensor(0.1698, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 16   | 1000  | tensor(0.0525, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 17   |   0   | tensor(0.0791, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 17   | 1000  | tensor(0.0678, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 18   |   0   | tensor(0.0377, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 18   | 1000  | tensor(0.1031, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  7   |   0   | tensor(0.1782, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  7   | 1000  | tensor(0.2121, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  8   |   0   | tensor(0.1662, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  8   | 1000  | tensor(0.1162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  9   |   0   | tensor(0.1099, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  9   | 1000  | tensor(0.1202, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 10   |   0   | tensor(0.0628, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 10   | 1000  | tensor(0.2052, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 11   |   0   | tensor(0.0696, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 11   | 1000  | tensor(0.1324, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 12   |   0   | tensor(0.1483, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 12   | 1000  | tensor(0.1027, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 13   |   0   | tensor(0.1050, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 13   | 1000  | tensor(0.0867, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 14   |   0   | tensor(0.0529, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 14   | 1000  | tensor(0.0234, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 15   |   0   | tensor(0.0961, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 15   | 1000  | tensor(0.0514, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 16   |   0   | tensor(0.1698, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 16   | 1000  | tensor(0.0525, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 17   |   0   | tensor(0.0791, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 17   | 1000  | tensor(0.0678, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 18   |   0   | tensor(0.0377, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 18   | 1000  | tensor(0.1031, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 19   |   0   | tensor(0.0261, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  7   |   0   | tensor(0.1782, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  7   | 1000  | tensor(0.2121, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  8   |   0   | tensor(0.1662, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  8   | 1000  | tensor(0.1162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  9   |   0   | tensor(0.1099, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  9   | 1000  | tensor(0.1202, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 10   |   0   | tensor(0.0628, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 10   | 1000  | tensor(0.2052, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 11   |   0   | tensor(0.0696, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 11   | 1000  | tensor(0.1324, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 12   |   0   | tensor(0.1483, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 12   | 1000  | tensor(0.1027, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 13   |   0   | tensor(0.1050, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 13   | 1000  | tensor(0.0867, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 14   |   0   | tensor(0.0529, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 14   | 1000  | tensor(0.0234, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 15   |   0   | tensor(0.0961, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 15   | 1000  | tensor(0.0514, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 16   |   0   | tensor(0.1698, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 16   | 1000  | tensor(0.0525, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 17   |   0   | tensor(0.0791, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 17   | 1000  | tensor(0.0678, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 18   |   0   | tensor(0.0377, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 18   | 1000  | tensor(0.1031, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 19   |   0   | tensor(0.0261, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  7   |   0   | tensor(0.1782, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  7   | 1000  | tensor(0.2121, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  8   |   0   | tensor(0.1662, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  8   | 1000  | tensor(0.1162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  9   |   0   | tensor(0.1099, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  9   | 1000  | tensor(0.1202, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 10   |   0   | tensor(0.0628, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 10   | 1000  | tensor(0.2052, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 11   |   0   | tensor(0.0696, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 11   | 1000  | tensor(0.1324, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 12   |   0   | tensor(0.1483, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 12   | 1000  | tensor(0.1027, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 13   |   0   | tensor(0.1050, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 13   | 1000  | tensor(0.0867, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 14   |   0   | tensor(0.0529, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 14   | 1000  | tensor(0.0234, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 15   |   0   | tensor(0.0961, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 15   | 1000  | tensor(0.0514, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 16   |   0   | tensor(0.1698, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 16   | 1000  | tensor(0.0525, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 17   |   0   | tensor(0.0791, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 17   | 1000  | tensor(0.0678, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 18   |   0   | tensor(0.0377, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 18   | 1000  | tensor(0.1031, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 19   |   0   | tensor(0.0261, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "| 19   | 1000  | tensor(0.0666, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.3284, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.1886, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(0.9485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(0.8413, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(0.7599, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   | 1000  | tensor(0.7460, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |   0   | tensor(0.3843, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   | 1000  | tensor(0.6317, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   |   0   | tensor(0.5950, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  4   | 1000  | tensor(0.3933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   |   0   | tensor(0.2530, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  5   | 1000  | tensor(0.3487, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   |   0   | tensor(0.2444, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  6   | 1000  | tensor(0.2965, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  7   |   0   | tensor(0.1782, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  7   | 1000  | tensor(0.2121, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  8   |   0   | tensor(0.1662, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  8   | 1000  | tensor(0.1162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  9   |   0   | tensor(0.1099, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  9   | 1000  | tensor(0.1202, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 10   |   0   | tensor(0.0628, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 10   | 1000  | tensor(0.2052, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 11   |   0   | tensor(0.0696, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 11   | 1000  | tensor(0.1324, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 12   |   0   | tensor(0.1483, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 12   | 1000  | tensor(0.1027, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 13   |   0   | tensor(0.1050, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 13   | 1000  | tensor(0.0867, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 14   |   0   | tensor(0.0529, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 14   | 1000  | tensor(0.0234, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 15   |   0   | tensor(0.0961, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 15   | 1000  | tensor(0.0514, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 16   |   0   | tensor(0.1698, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 16   | 1000  | tensor(0.0525, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 17   |   0   | tensor(0.0791, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 17   | 1000  | tensor(0.0678, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 18   |   0   | tensor(0.0377, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 18   | 1000  | tensor(0.1031, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 19   |   0   | tensor(0.0261, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "| 19   | 1000  | tensor(0.0666, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[07:41:12] </span><span style=\"font-weight: bold\">[</span>Initiating Validation<span style=\"font-weight: bold\">]</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">&lt;ipython-input-11-91b2f7e68627&gt;:87</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                  </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[07:41:12]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mInitiating Validation\u001b[1m]\u001b[0m\u001b[33m...\u001b[0m                                            \u001b[2m<ipython-input-11-91b2f7e68627>\u001b[0m\u001b[2m:\u001b[0m\u001b[2m87\u001b[0m\n",
       "\u001b[2;36m           \u001b[0m                                                                      \u001b[2m                                  \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"font-weight: bold\">[</span>Validation Completed.<span style=\"font-weight: bold\">]</span>                                               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">&lt;ipython-input-11-91b2f7e68627&gt;:95</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                  </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mValidation Completed.\u001b[1m]\u001b[0m                                               \u001b[2m<ipython-input-11-91b2f7e68627>\u001b[0m\u001b[2m:\u001b[0m\u001b[2m95\u001b[0m\n",
       "\u001b[2;36m           \u001b[0m                                                                      \u001b[2m                                  \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>Model<span style=\"font-weight: bold\">]</span> Model saved @ .<span style=\"color: #800080; text-decoration-color: #800080\">/drive/MyDrive/T5/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">model_files</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0mModel\u001b[1m]\u001b[0m Model saved @ .\u001b[35m/drive/MyDrive/T5/\u001b[0m\u001b[95mmodel_files\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>Validation<span style=\"font-weight: bold\">]</span> Generation on Validation data saved @ .<span style=\"color: #800080; text-decoration-color: #800080\">/drive/MyDrive/T5/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">predictions.csv</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0mValidation\u001b[1m]\u001b[0m Generation on Validation data saved @ .\u001b[35m/drive/MyDrive/T5/\u001b[0m\u001b[95mpredictions.csv\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>Logs<span style=\"font-weight: bold\">]</span> Logs saved @ .<span style=\"color: #800080; text-decoration-color: #800080\">/drive/MyDrive/T5/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">logs.txt</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0mLogs\u001b[1m]\u001b[0m Logs saved @ .\u001b[35m/drive/MyDrive/T5/\u001b[0m\u001b[95mlogs.txt\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "T5Trainer(dataframe=dfAll, source_text=\"question\", target_text=\"answer\", model_params=model_params, output_dir=\"./drive/MyDrive/T5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "unvWOxvkJUsR"
   },
   "outputs": [],
   "source": [
    "result = pd.read_csv('drive/MyDrive/T5/predictions.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O8HCqo1tI07Y"
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "results = bleu.compute(predictions=result['Generated Text'], references=result['Actual Text'])\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7GaPp41HM4RJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "41a0hXcVsiMb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
