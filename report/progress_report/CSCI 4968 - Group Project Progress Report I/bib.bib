@incollection{plutchik1980general,
  title={A general psychoevolutionary theory of emotion},
  author={Plutchik, Robert},
  booktitle={Theories of emotion},
  pages={3--33},
  year={1980},
  publisher={Elsevier}
}

@article{MingWeiChang2018BERTPO,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Ming-Wei Chang and Kenton Lee and Kristina Toutanova and Jacob Devlin},
  journal={north american chapter of the association for computational linguistics},
  year={2018}
}

@misc{https://doi.org/10.48550/arxiv.1506.01497,
  doi = {10.48550/ARXIV.1506.01497},
  
  url = {https://arxiv.org/abs/1506.01497},
  
  author = {Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks},
  
  publisher = {arXiv},
  
  year = {2015},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{mostafazadeh2016corpus,
      title={A Corpus and Evaluation Framework for Deeper Understanding of Commonsense Stories}, 
      author={Nasrin Mostafazadeh and Nathanael Chambers and Xiaodong He and Devi Parikh and Dhruv Batra and Lucy Vanderwende and Pushmeet Kohli and James Allen},
      year={2016},
      eprint={1604.01696},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@inproceedings{lin-och-2004-orange,
    title = "{ORANGE}: a Method for Evaluating Automatic Evaluation Metrics for Machine Translation",
    author = "Lin, Chin-Yew  and
      Och, Franz Josef",
    booktitle = "{COLING} 2004: Proceedings of the 20th International Conference on Computational Linguistics",
    month = "aug 23{--}aug 27",
    year = "2004",
    address = "Geneva, Switzerland",
    publisher = "COLING",
    url = "https://www.aclweb.org/anthology/C04-1072",
    pages = "501--507",
}

@misc{https://doi.org/10.48550/arxiv.1904.09675,
  doi = {10.48550/ARXIV.1904.09675},
  
  url = {https://arxiv.org/abs/1904.09675},
  
  author = {Zhang, Tianyi and Kishore, Varsha and Wu, Felix and Weinberger, Kilian Q. and Artzi, Yoav},
  
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {BERTScore: Evaluating Text Generation with BERT},
  
  publisher = {arXiv},
  
  year = {2019},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@software{glenn_jocher_2022_6222936,
  author       = {Glenn Jocher and
                  Ayush Chaurasia and
                  Alex Stoken and
                  Jirka Borovec and
                  NanoCode012 and
                  Yonghye Kwon and
                  TaoXie and
                  Jiacong Fang and
                  imyhxy and
                  Kalen Michael and
                  Lorna and
                  Abhiram V and
                  Diego Montes and
                  Jebastin Nadar and
                  Laughing and
                  tkianai and
                  yxNONG and
                  Piotr Skalski and
                  Zhiqiang Wang and
                  Adam Hogan and
                  Cristi Fati and
                  Lorenzo Mammana and
                  AlexWang1900 and
                  Deep Patel and
                  Ding Yiwei and
                  Felix You and
                  Jan Hajek and
                  Laurentiu Diaconu and
                  Mai Thanh Minh},
  title        = {{ultralytics/yolov5: v6.1 - TensorRT, TensorFlow 
                   Edge TPU and OpenVINO Export and Inference}},
  month        = feb,
  year         = 2022,
  publisher    = {Zenodo},
  version      = {v6.1},
  doi          = {10.5281/zenodo.6222936},
  url          = {https://doi.org/10.5281/zenodo.6222936}
}

@misc{https://doi.org/10.48550/arxiv.1405.0312,
  doi = {10.48550/ARXIV.1405.0312},
  
  url = {https://arxiv.org/abs/1405.0312},
  
  author = {Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Bourdev, Lubomir and Girshick, Ross and Hays, James and Perona, Pietro and Ramanan, Deva and Zitnick, C. Lawrence and Dollár, Piotr},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Microsoft COCO: Common Objects in Context},
  
  publisher = {arXiv},
  
  year = {2014},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{https://doi.org/10.48550/arxiv.1512.03385,
  doi = {10.48550/ARXIV.1512.03385},
  
  url = {https://arxiv.org/abs/1512.03385},
  
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Deep Residual Learning for Image Recognition},
  
  publisher = {arXiv},
  
  year = {2015},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{https://doi.org/10.48550/arxiv.1612.03144,
  doi = {10.48550/ARXIV.1612.03144},
  
  url = {https://arxiv.org/abs/1612.03144},
  
  author = {Lin, Tsung-Yi and Dollár, Piotr and Girshick, Ross and He, Kaiming and Hariharan, Bharath and Belongie, Serge},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Feature Pyramid Networks for Object Detection},
  
  publisher = {arXiv},
  
  year = {2016},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{https://doi.org/10.48550/arxiv.2103.00020,
  doi = {10.48550/ARXIV.2103.00020},
  
  url = {https://arxiv.org/abs/2103.00020},
  
  author = {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Learning Transferable Visual Models From Natural Language Supervision},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{https://doi.org/10.48550/arxiv.2102.12092,
  doi = {10.48550/ARXIV.2102.12092},
  
  url = {https://arxiv.org/abs/2102.12092},
  
  author = {Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Zero-Shot Text-to-Image Generation},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@inproceedings{banarjee2005,
  title     = {{METEOR}: An Automatic Metric for {MT} Evaluation with Improved Correlation with Human Judgments},
  author    = {Banerjee, Satanjeev  and Lavie, Alon},
  booktitle = {Proceedings of the {ACL} Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization},
  month     = jun,
  year      = {2005},
  address   = {Ann Arbor, Michigan},
  publisher = {Association for Computational Linguistics},
  url       = {https://www.aclweb.org/anthology/W05-0909},
  pages     = {65--72},
}

@inproceedings{post-2018-call,
    title = "A Call for Clarity in Reporting {BLEU} Scores",
    author = "Post, Matt",
    booktitle = "Proceedings of the Third Conference on Machine Translation: Research Papers",
    month = oct,
    year = "2018",
    address = "Belgium, Brussels",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6319",
    pages = "186--191",
}

@inproceedings{Meehan1977TALESPINAI,
  title={TALE-SPIN, An Interactive Program that Writes Stories},
  author={James R. Meehan},
  booktitle={IJCAI},
  year={1977}
}

@article{Riedl_2010,
	doi = {10.1613/jair.2989},
  
	url = {https://doi.org/10.1613%2Fjair.2989},
  
	year = 2010,
	month = {sep},
  
	publisher = {{AI} Access Foundation},
  
	volume = {39},
  
	pages = {217--268},
  
	author = {M. O. Riedl and R. M. Young},
  
	title = {Narrative Planning: Balancing Plot and Character},
  
	journal = {Journal of Artificial Intelligence Research}
}

@Book{ nla.cat-vn485880,
author = { Turner, Scott R. },
title = { The creative process : a computer model of storytelling and creativity / Scott R. Turner },
isbn = { 0805815767 },
publisher = { L. Erlbaum Hillsdale, N.J },
pages = { ix, 298 p. ; },
year = { 1994 },
type = { Book },
language = { English },
subjects = { Authorship -- Data processing.; Storytelling -- Data processing. },
life-dates = { 1994 -  },
catalogue-url = { https://nla.gov.au/nla.cat-vn485880 },
}

@inproceedings{Gervs2005StoryPG,
  title={Story plot generation based on CBR},
  author={Pablo Gerv{\'a}s and Bel{\'e}n D{\'i}az-Agudo and Federico Peinado and Raquel Herv{\'a}s},
  booktitle={Knowl. Based Syst.},
  year={2005}
}
@article{Montfort,
author = {Montfort, Nick},
year = {2007},
month = {01},
pages = {},
title = {Generating narrative variation in interactive fiction},
journal = {Dissertations available from ProQuest}
}

@article{10.1145/2362394.2362398,
author = {Swanson, Reid and Gordon, Andrew S.},
title = {Say Anything: Using Textual Case-Based Reasoning to Enable Open-Domain Interactive Storytelling},
year = {2012},
issue_date = {September 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {3},
issn = {2160-6455},
url = {https://doi.org/10.1145/2362394.2362398},
doi = {10.1145/2362394.2362398},
abstract = {We describe Say Anything, a new interactive storytelling system that collaboratively writes textual narratives with human users. Unlike previous attempts, this interactive storytelling system places no restrictions on the content or direction of the user’s contribution to the emerging storyline. In response to these contributions, the computer continues the storyline with narration that is both coherent and entertaining. This capacity for open-domain interactive storytelling is enabled by an extremely large repository of nonfiction personal stories, which is used as a knowledge base in a case-based reasoning architecture. In this article, we describe the three main components of our case-based reasoning approach: a million-item corpus of personal stories mined from internet weblogs, a case retrieval strategy that is optimized for narrative coherence, and an adaptation strategy that ensures that repurposed sentences from the case base are appropriate for the user’s emerging fiction. We describe a series of evaluations of the system’s ability to produce coherent and entertaining stories, and we compare these narratives with single-author stories posted to internet weblogs.},
journal = {ACM Trans. Interact. Intell. Syst.},
month = {sep},
articleno = {16},
numpages = {35},
keywords = {case-based reasoning, Interactive Storytelling, weblogs and social media}
}

@article{Li,
author = {Li, Boyang and Lee-Urban, S. and Johnston, G. and Riedl, Mark},
year = {2013},
month = {01},
pages = {598-604},
title = {Story generation with crowdsourced plot graphs},
journal = {Proceedings of the 27th AAAI Conference on Artificial Intelligence, AAAI 2013}
}

@inproceedings{NIPS2015_f442d33f,
 author = {Kiros, Ryan and Zhu, Yukun and Salakhutdinov, Russ R and Zemel, Richard and Urtasun, Raquel and Torralba, Antonio and Fidler, Sanja},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {C. Cortes and N. Lawrence and D. Lee and M. Sugiyama and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Skip-Thought Vectors},
 url = {https://proceedings.neurips.cc/paper/2015/file/f442d33fa06832082290ad8544a8da27-Paper.pdf},
 volume = {28},
 year = {2015}
}

@inproceedings{mostafazadeh-etal-2016-caters,
    title = "{C}a{T}e{RS}: Causal and Temporal Relation Scheme for Semantic Annotation of Event Structures",
    author = "Mostafazadeh, Nasrin  and
      Grealish, Alyson  and
      Chambers, Nathanael  and
      Allen, James  and
      Vanderwende, Lucy",
    booktitle = "Proceedings of the Fourth Workshop on Events",
    month = jun,
    year = "2016",
    address = "San Diego, California",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W16-1007",
    doi = "10.18653/v1/W16-1007",
    pages = "51--61",
}

@inproceedings{fan-etal-2018-hierarchical,
    title = "Hierarchical Neural Story Generation",
    author = "Fan, Angela  and
      Lewis, Mike  and
      Dauphin, Yann",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P18-1082",
    doi = "10.18653/v1/P18-1082",
    pages = "889--898",
    abstract = "We explore story generation: creative systems that can build coherent and fluent passages of text about a topic. We collect a large dataset of 300K human-written stories paired with writing prompts from an online forum. Our dataset enables hierarchical story generation, where the model first generates a premise, and then transforms it into a passage of text. We gain further improvements with a novel form of model fusion that improves the relevance of the story to the prompt, and adding a new gated multi-scale self-attention mechanism to model long-range context. Experiments show large improvements over strong baselines on both automated and human evaluations. Human judges prefer stories generated by our approach to those from a strong non-hierarchical model by a factor of two to one.",
}

@book{onega2014narratology,
  title={Narratology: an introduction},
  author={Onega, Susana and Landa, Jos{\'e} Angel Garc{\'\i}a},
  year={2014},
  publisher={Routledge}
}

@article{mostafazadeh2016corpus,
  title={A corpus and evaluation framework for deeper understanding of commonsense stories},
  author={Mostafazadeh, Nasrin and Chambers, Nathanael and He, Xiaodong and Parikh, Devi and Batra, Dhruv and Vanderwende, Lucy and Kohli, Pushmeet and Allen, James},
  journal={arXiv preprint arXiv:1604.01696},
  year={2016}
}

@Article{jimaging8020018,
AUTHOR = {Ibrahim, Bekkouch Imad Eddine and Eyharabide, Victoria and Le Page, Valérie and Billiet, Frédéric},
TITLE = {Few-Shot Object Detection: Application to Medieval Musicological Studies},
JOURNAL = {Journal of Imaging},
VOLUME = {8},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {18},
URL = {https://www.mdpi.com/2313-433X/8/2/18},
ISSN = {2313-433X},
ABSTRACT = {Detecting objects with a small representation in images is a challenging task, especially when the style of the images is very different from recent photos, which is the case for cultural heritage datasets. This problem is commonly known as few-shot object detection and is still a new field of research. This article presents a simple and effective method for black box few-shot object detection that works with all the current state-of-the-art object detection models. We also present a new dataset called MMSD for medieval musicological studies that contains five classes and 693 samples, manually annotated by a group of musicology experts. Due to the significant diversity of styles and considerable disparities between the artistic representations of the objects, our dataset is more challenging than the current standards. We evaluate our method on YOLOv4 (m/s), (Mask/Faster) RCNN, and ViT/Swin-t. We present two methods of benchmarking these models based on the overall data size and the worst-case scenario for object detection. The experimental results show that our method always improves object detector results compared to traditional transfer learning, regardless of the underlying architecture.},
DOI = {10.3390/jimaging8020018}
}

@misc{https://doi.org/10.48550/arxiv.2102.06529,
  doi = {10.48550/ARXIV.2102.06529},
  
  url = {https://arxiv.org/abs/2102.06529},
  
  author = {Kadish, David and Risi, Sebastian and Løvlie, Anders Sundnes},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences, I.4.8},
  
  title = {Improving Object Detection in Art Images Using Only Style Transfer},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@misc{https://doi.org/10.48550/arxiv.2201.11903,
  doi = {10.48550/ARXIV.2201.11903},
  
  url = {https://arxiv.org/abs/2201.11903},
  
  author = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed and Le, Quoc and Zhou, Denny},
  
  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Chain of Thought Prompting Elicits Reasoning in Large Language Models},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@inproceedings{yang-etal-2019-enhancing-topic,
    title = "Enhancing Topic-to-Essay Generation with External Commonsense Knowledge",
    author = "Yang, Pengcheng  and
      Li, Lei  and
      Luo, Fuli  and
      Liu, Tianyu  and
      Sun, Xu",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1193",
    doi = "10.18653/v1/P19-1193",
    pages = "2002--2012",
    abstract = "Automatic topic-to-essay generation is a challenging task since it requires generating novel, diverse, and topic-consistent paragraph-level text with a set of topics as input. Previous work tends to perform essay generation based solely on the given topics while ignoring massive commonsense knowledge. However, this commonsense knowledge provides additional background information, which can help to generate essays that are more novel and diverse. Towards filling this gap, we propose to integrate commonsense from the external knowledge base into the generator through dynamic memory mechanism. Besides, the adversarial training based on a multi-label discriminator is employed to further improve topic-consistency. We also develop a series of automatic evaluation metrics to comprehensively assess the quality of the generated essay. Experiments show that with external commonsense knowledge and adversarial training, the generated essays are more novel, diverse, and topic-consistent than existing methods in terms of both automatic and human evaluation.",
}

@inproceedings{Tambwekar2019ControllableNS,
  title={Controllable Neural Story Plot Generation via Reward Shaping},
  author={Pradyumna Tambwekar and Murtaza Dhuliawala and Lara J. Martin and Animesh Mehta and Brent Harrison and Mark O. Riedl},
  booktitle={IJCAI},
  year={2019}
}

@article{Liu_Li_Yu_Huang_Liu_Zhao_Yan_2020, title={A Character-Centric Neural Model for Automated Story Generation}, volume={34}, url={https://ojs.aaai.org/index.php/AAAI/article/view/5536}, DOI={10.1609/aaai.v34i02.5536}, abstractNote={&lt;p&gt;Automated story generation is a challenging task which aims to automatically generate convincing stories composed of successive plots correlated with consistent characters. Most recent generation models are built upon advanced neural networks, e.g., variational autoencoder, generative adversarial network, convolutional sequence to sequence model. Although these models have achieved prompting results on learning linguistic patterns, very few methods consider the attributes and prior knowledge of the story genre, especially from the perspectives of explainability and consistency. To fill this gap, we propose a character-centric neural storytelling model, where a story is created encircling the given character, i.e., each part of a story is conditioned on a given character and corresponded context environment. In this way, we explicitly capture the character information and the relations between plots and characters to improve explainability and consistency. Experimental results on open dataset indicate that our model yields meaningful improvements over several strong baselines on both human and automatic evaluations.&lt;/p&gt;}, number={02}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Liu, Danyang and Li, Juntao and Yu, Meng-Hsuan and Huang, Ziming and Liu, Gongshen and Zhao, Dongyan and Yan, Rui}, year={2020}, month={Apr.}, pages={1725-1732} }

@unpublished{spacy2,
    AUTHOR = {Honnibal, Matthew and Montani, Ines},
    TITLE  = {{spaCy 2}: Natural language understanding with {B}loom embeddings, convolutional neural networks and incremental parsing},
    YEAR   = {2017},
    Note   = {To appear}
}

@article{Zhou_Huang_Zhang_Zhu_Liu_2018, title={Emotional Chatting Machine: Emotional Conversation Generation with Internal and External Memory}, volume={32}, url={https://ojs.aaai.org/index.php/AAAI/article/view/11325}, DOI={10.1609/aaai.v32i1.11325}, abstractNote={ &lt;p&gt; Perception and expression of emotion are key factors to the success of dialogue systems or conversational agents. However, this problem has not been studied in large-scale conversation generation so far. In this paper, we propose Emotional Chatting Machine (ECM) that can generate appropriate responses not only in content (relevant and grammatical) but also in emotion (emotionally consistent). To the best of our knowledge, this is the first work that addresses the emotion factor in large-scale conversation generation. ECM addresses the factor using three new mechanisms that respectively (1) models the high-level abstraction of emotion expressions by embedding emotion categories, (2) captures the change of implicit internal emotion states, and (3) uses explicit emotion expressions with an external emotion vocabulary. Experiments show that the proposed model can generate responses appropriate not only in content but also in emotion. &lt;/p&gt; }, number={1}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Zhou, Hao and Huang, Minlie and Zhang, Tianyang and Zhu, Xiaoyan and Liu, Bing}, year={2018}, month={Apr.} }

@article{lin2019commongen,
  title={CommonGen: A constrained text generation challenge for generative commonsense reasoning},
  author={Lin, Bill Yuchen and Zhou, Wangchunshu and Shen, Ming and Zhou, Pei and Bhagavatula, Chandra and Choi, Yejin and Ren, Xiang},
  journal={arXiv preprint arXiv:1911.03705},
  year={2019}
}

@inproceedings{commonsense,
  author    = {Hannah Rashkin and
               Antoine Bosselut and
               Maarten Sap and
               Kevin Knight and
               Yejin Choi},
  editor    = {Iryna Gurevych and
               Yusuke Miyao},
  title     = {Modeling Naive Psychology of Characters in Simple Commonsense Stories},
  booktitle = {Proceedings of the 56th Annual Meeting of the Association for Computational
               Linguistics, {ACL} 2018, Melbourne, Australia, July 15-20, 2018, Volume
               1: Long Papers},
  pages     = {2289--2299},
  publisher = {Association for Computational Linguistics},
  year      = {2018},
  url       = {https://aclanthology.org/P18-1213/},
  doi       = {10.18653/v1/P18-1213},
  timestamp = {Fri, 06 Aug 2021 00:41:00 +0200},
  biburl    = {https://dblp.org/rec/conf/acl/KnightCSRB18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer.},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J and others},
  journal={J. Mach. Learn. Res.},
  volume={21},
  number={140},
  pages={1--67},
  year={2020}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@inproceedings{rombach2022high,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10684--10695},
  year={2022}
}


@inproceedings{wu2019unified,
  title={Unified visual-semantic embeddings: Bridging vision and language with structured meaning representations},
  author={Wu, Hao and Mao, Jiayuan and Zhang, Yufeng and Jiang, Yuning and Li, Lei and Sun, Weiwei and Ma, Wei-Ying},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6609--6618},
  year={2019}
}