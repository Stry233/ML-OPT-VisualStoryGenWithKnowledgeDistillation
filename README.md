# Ml&Opt - Leveraging Large Language Models for Creative Story Generation

This is a project repository for Spring 2023 CSCI 4968 - Machince Learning and Optimization 
## Background: 

Story generation is an emerging research area in natural language processing that aims to automatically generate coherent and engaging stories. Large Language Models (LLMs) such as GPT-3 have demonstrated impressive capabilities in generating human-like text and can be a promising solution for creative story generation. However, generating coherent and engaging stories that follow a narrative structure remains a challenging task, as it requires more than just generating a sequence of words.

## Objective: 

The objective of this research is to investigate the potential of LLMs for creative story generation by leveraging their capabilities for generating human-like text and exploring novel techniques for narrative structure generation. We aim to develop a framework that can generate coherent and engaging stories with rich narrative structures, including character development, plot progression, and conflict resolution.

## Methodology: 

We will use a pre-trained LLM such as T5 as the foundation of our story generation framework. We will explore different techniques for generating narrative structures, such as using knowledge graphs to represent characters and plot elements and controlling the generation process to ensure coherence and consistency. We will also use a fine-tuning approach to adapt the LLM to the task of story generation and improve its performance in generating coherent and engaging stories.

## Expected Results

We expect to develop a framework that can generate coherent and engaging stories with rich narrative structures, including character development, plot progression, and conflict resolution. We also anticipate that our framework will be able to generate stories that are engaging and can be enjoyed by a wide audience. Furthermore, we expect to identify the most effective techniques for narrative structure generation and fine-tuning the LLM for story generation.
